<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>HVX-specific optimization - Ripple HVX Optimization Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-67fe224f.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-8f2f9eff.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Ripple HVX Optimization Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="hexagon-r-hvx-optimization"><a class="header" href="#hexagon-r-hvx-optimization">Hexagon (R) HVX Optimization</a></h1>
<p>This section is structured as a list of coding recommendations
in order to get competitive performance out of your Ripple programs.</p>
<h1 id="optimization-level"><a class="header" href="#optimization-level">Optimization level</a></h1>
<p>Ripple has been most tested with the <code>-O2</code> option on HVX,
which seems to be the most common optimization level.</p>
<pre><code class="language-bash">clang -O2 ...
</code></pre>
<h1 id="vector-size-parameters"><a class="header" href="#vector-size-parameters">Vector size parameters</a></h1>
<p>Current versions of HVX ISAs tend to come with a register file of 32Kb total.
Please check the appropriate programmer’s manuals for any specific information,
such as number and bit-width of registers,
about the particular architecture version you are compiling for.
The following block sizes illustrate single-vector block sizes
assuming a vector width of 1024 bits.</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>element type</th><th>i8/u8</th><th>i16/u16/f16</th><th>i32/u32/f32</th></tr>
</thead>
<tbody>
<tr><td>single-vector block size</td><td>128</td><td>64</td><td>32</td></tr>
</tbody>
</table>
</div>
<p>Since HVX instruction packets can contain up to four instructions, it is usually not useful to make the size of your block larger than four vectors.
For more information about VLIW slot usage, please consult the Hexagon HVX Programmer’s Reference Manual (available on <code>docs.qualcomm.com</code>).</p>
<h1 id="make-the-type-of-constants-immediates-explicit"><a class="header" href="#make-the-type-of-constants-immediates-explicit">Make the type of constants (“immediates”) explicit</a></h1>
<p><strong>Performance impact</strong>: High.</p>
<p>One thing to remember when coding in Ripple, is that it maintains all semantical aspects of its underlying language.
One aspect of C that can impact performance in C and C++ is their <strong>implicit type conversions</strong>, and the <strong>default type</strong> for its constants.</p>
<p><strong>Example 1.</strong> Consider the following function, which doubles the value of a <code>float</code> array.</p>
<pre><code class="language-c">1:void double_me(float * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 32);
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = 2.0 * A[i];
6:  }
7:}
</code></pre>
<p><strong>Problem</strong>: The <code>2.0</code> immediate is by default a <code>double</code> in C and C++.
Also, type promotion rules in C/C++ indicate that the multiplication line 5 is done after promoting both operands to the same type, <code>double</code>.
Hence, Ripple tries to produce a SIMD multiplication of 32 doubles.
However, current versions of HVX do not support SIMD
double-precision instructions.
As a result, the generated code is sequentialized, resulting in an order of magnitude slower performance than if SIMD could have been used.</p>
<p><strong>Solution</strong>: Make the <code>2.0</code> immediate explicitly of the <code>float</code> type, using the <code>f</code> suffix.</p>
<pre><code class="language-c">5:     A[i] = 2.0f * A[i];
</code></pre>
<p>The same issue can happen with integers, for which the default type is <code>int</code>, as in the following example:</p>
<pre><code class="language-c">1:void double_me(short * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 64);
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = 2 * A[i];
6:  }
7:}
</code></pre>
<p>Here, the <code>2</code> line 5 is an <code>int</code>, and so is the subsequent multiplication,
because of type promotion rules in the C programming language.
<strong>Solution</strong>: convert it to short explicitly.</p>
<pre><code class="language-c">5:    A[i] = ((short) 2) * A[i];
</code></pre>
<p>If you are using C++, precomputing it and forcing it to be a constexpr
will make sure that there is no extra cost to this conversion, as in the following code:</p>
<pre><code class="language-c++">1:void double_me(short * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 64);
3:  constexpr short two = (short) 2;
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = two * A[i];
6:  }
7:}
</code></pre>
<h1 id="optimizing-floating-point-code"><a class="header" href="#optimizing-floating-point-code">Optimizing floating-point code</a></h1>
<h2 id="use-floating-point-types-up-to-32-bit-wide-float-only"><a class="header" href="#use-floating-point-types-up-to-32-bit-wide-float-only">Use floating point types up to 32-bit wide (<code>float</code>) only</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<p>Hexagon supports two native floating-point types: float and _Float16.
__bf16 is partially emulated.
There isn’t currently a native HVX <code>double</code> vector ISA.
Hence, avoid double-precision computations in your vector codes,
which will come out as sequentialized.</p>
<h2 id="leverage-compiler-flags"><a class="header" href="#leverage-compiler-flags">Leverage compiler flags</a></h2>
<h3 id="extended-precision"><a class="header" href="#extended-precision">Extended precision</a></h3>
<p><strong>Performance impact</strong>: Medium.</p>
<p>HVX allows extended-precision computations to happen in sequences of floating-point operations happening between memory accesses.
These are in a way more precise than IEEE floating-point, but they will result in a different numerical result from the same computation performed on IEEE floating point numbers.
It is possible to forgo of extended precision and be fully compatible with IEEE. However, this comes at a performance cost.</p>
<p>The use of fast, extended precision vs. slower, IEEE-compliant precision, is controlled by the following flag:</p>
<pre><code class="language-bash">-mhvx-qfloat=&lt;mode&gt;
</code></pre>
<p>We refer to the HVX manual to describe the exact behavior of the following four modes:</p>
<ul>
<li><code>strict-ieee</code> will give you full compatibility with IEEE floating point.</li>
<li><code>ieee</code> uses extended precision for some operations.</li>
<li><code>lossy</code> uses extended precision for more operations.</li>
<li><code>legacy</code> uses extended precision for almost all operations.</li>
</ul>
<p>As of clang 21.0, the default is set to <code>lossy</code>.
<strong>Warning</strong>: the <code>lossy</code> option also implies other flags that impact precision, such as <code>-ffast-math</code>, which declares that floating-point (+, *) operations are commutative and associative, and that the data is free of <code>NaN</code>s and infinity.</p>
<h3 id="working-with-finite-values"><a class="header" href="#working-with-finite-values">Working with finite values</a></h3>
<p><strong>Performance impact</strong>: Low.</p>
<p>clang is able to optimize some codes when you know that your floating-point values are always defined (they are not a NaN) and never infinite.
If you are in that case, use the <code>-ffinite-only</code> command-line flag.</p>
<h3 id="relaxing-the-ordering-of-computations"><a class="header" href="#relaxing-the-ordering-of-computations">Relaxing the ordering of computations</a></h3>
<p><strong>Performance impact</strong>: Medium.</p>
<p>Addition and multiplication are commutative and associative for real numbers. This means that you can change the order in which a sequence of (for instance) additions (often called “reductions”) are computed without changing the result.
Being able to change this order allows compilers to execute such sequences of operations faster.</p>
<p>Floating point numbers are an approximation for real numbers, and as a consequence, their operations aren’t associative strictly speaking.
Changing the order of floating-point computations typically introduces some amount of precision error.</p>
<p><strong>Solution</strong> If your computation tolerates some amount of floating-point error, or if semantically that order does not matter for the resulting computation, you can let Ripple know it, using the following command-line flag:</p>
<pre><code class="language-bash">clang -fassociative-math
</code></pre>
<p>This will speed up some computations, including reductions (expressed through the <code>ripple_reduce_*()</code> ripple API).</p>
<h3 id="fast-conversions-from-floating-point-to-integer"><a class="header" href="#fast-conversions-from-floating-point-to-integer">Fast conversions from floating-point to integer</a></h3>
<p><strong>Performance impact</strong>: Low.</p>
<p>Conversion from floating-point (<code>Float</code> and <code>float</code> types) to integer
(<code>int16_t</code> and <code>int32_t</code>) can be slow,
as clang tries to implement it as precisely as possible.</p>
<p><strong>Solution</strong> Enable fast floating-point conversion,
which is very close semantically, but uses a single instruction.
To enable it, use the following command-line flag:</p>
<pre><code class="language-bash">clang -mllvm -hexagon-fp-fast-convert=true ...
</code></pre>
<h1 id="using-ripple_shuffle-on-vector-pairs"><a class="header" href="#using-ripple_shuffle-on-vector-pairs">Using ripple_shuffle on vector pairs</a></h1>
<p><strong>Performance impact</strong>: Medium.</p>
<p>We empirically noticed that shuffles on blocks of 2 vectors tend to
generate more efficient machine code.</p>
<h1 id="inlining-functions"><a class="header" href="#inlining-functions">Inlining functions</a></h1>
<p><strong>Performance impact</strong>: High.</p>
<p>For an HVX target, there are significant overheads associated with function calls.
The overheads mostly arise from saving the register frame onto the stack
before the function call and loading the register frame from the stack
after the call returns.
Consequently, we advise the programmer to utilize clang’s
<a href="https://clang.llvm.org/docs/AttributeReference.html#always-inline-force-inline">“always_inline”</a>
function attribute.
Avoid these overheads while maintaining code-readability as follows:</p>
<pre><code class="language-C"> static int foo(int a, int b) __attribute__((always_inline)) {
    /// ...
  }
</code></pre>
<p>or in C++</p>
<pre><code class="language-C++">static int foo(int a, int b) [[gnu::always_inline]] {
    /// ...
  }
</code></pre>
<h1 id="functions-optimized-for-hvx"><a class="header" href="#functions-optimized-for-hvx">Functions optimized for HVX</a></h1>
<h2 id="high-throughput-data-reordering-scattergather"><a class="header" href="#high-throughput-data-reordering-scattergather">High-throughput data reordering (scatter/gather)</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<p>Loading from a collection of arbitrary addresses into a vector
is by construction a long-latency operation,
as it can result in bank conflicts.
Hence, we do not recommend the direct use of non-coalesced access functions.</p>
<p>However, the Ripple vector library includes a
high-bandwidth memory-to-memory copying API for HVX,
which can move large amounts of data in parallel
(still with the same type of latency).</p>
<p>In cases where we cannot change our computations
to create coalesced data accesses, we can still rearrange our data into a set
that can be accessed in a coalesced way a bit later,
using the <code>hvx_gather/hvx_scatter</code> API.</p>
<p>Use cases for scatter-gather include indirections (<code>A[B[i]]</code>),
large lookup tables, sparse-dense array computations (for instance sparse matrix dense vector multiplication), and strided data accesses, particularly when the data access stride is large (e.g. when accessing element of a large array along columns).
We refer to the Ripple manual for a more complete description of
<code>hvx_scatter</code> and <code>hvx_gather</code>.</p>
<h2 id="explicit-bfloat16-conversions"><a class="header" href="#explicit-bfloat16-conversions">Explicit bfloat16 conversions</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<p>Ripple supports three types of conversions from <code>float</code> to <code>__bf16</code>:</p>
<ul>
<li><code>to_bf_trunc</code>, a direct truncation</li>
<li><code>to_bf_nan</code>, a truncation that avoids incorrect NaN conversions (they can become an infinity using the direct shift)</li>
<li><code>to_bf_round</code>, a conversion that performs an even rounding and avoids incorrect Nan conversions. The behavior of this conversion is compatible with x86 bfloat conversion.</li>
</ul>
<h2 id="dynamic-rotations"><a class="header" href="#dynamic-rotations">Dynamic rotations</a></h2>
<p><strong>Performance impact</strong>: Low.</p>
<p><code>hvx_rotate(x, n)</code> will consider x flat (irrespective of its shape) and rotate the elements towards n lower indices
(e.g. the element at position 3+n goes to position 3).
One valuable aspect of this function is that <code>n</code> doesn’t need to be
a compile-time constant.
<code>n</code> could be a loop counter, for instance.</p>
<h2 id="narrowing-shifts"><a class="header" href="#narrowing-shifts">Narrowing shifts</a></h2>
<p><strong>Performance impact</strong>: Medium.</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<pre><code class="language-C">narrow_t hvx_narsh[[_rnd]_sat][_noshuff](wide_t odd, wide_t even, uint32 shift);
</code></pre>
<p>A narrowing shift (or “narsh”) is an operation on integers,
which performs a right shift followed by a conversion
to a smaller integer type.
The conversion can be done by truncation or using saturation (using the function name suffix <code>_sat</code>).
When saturation is used, we can also request rounding up, using the
<code>_sat_rnd</code> suffix.
The shift amount sh is the same for all elements of the block.</p>
<p>Two forms are supported. The first, faster form takes two inputs, performs a narrowing shift, and shuffles the resulting block.
The second form, suffixed with <code>_noshuff</code>, doesn’t shuffle the result.</p>
<h3 id="supported-source-and-destination-types-__"><a class="header" href="#supported-source-and-destination-types-__">Supported source and destination types __</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>wide (source) type</th><th>narrow (destination) type</th></tr>
</thead>
<tbody>
<tr><td>i32 (int32_t)</td><td>i16, u16</td></tr>
<tr><td>u32 (uint32_t)</td><td>u16</td></tr>
<tr><td>i16 (int16_t)</td><td>i8, u8</td></tr>
<tr><td>u16</td><td>u8</td></tr>
</tbody>
</table>
</div>
<p>An interesting aspect of this function is that it packs
the narrowed by pairs, i.e. two 32-bit integers get narrowed and packed into one 32-bit integer.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<pre><code class="language-C">int16_t hvx_narsh_sat_i16toi8(int16_t odd, int16_t even, uint32_t shift);
uint32_t hvx_narsh_rnd_sat_u32tou16_noshuff(uint32_t odd, uint32_t even, uint32_t shift);
</code></pre>
<h3 id="constraints"><a class="header" href="#constraints">Constraints</a></h3>
<p>hvx_narsh works on block sizes that occupy a full HVX vector.</p>
<h2 id="chunked-zipping-and-unzipping-for-pairs-of-hvx-vectors"><a class="header" href="#chunked-zipping-and-unzipping-for-pairs-of-hvx-vectors">Chunked zipping and unzipping for pairs of HVX vectors</a></h2>
<p><strong>Performance impact</strong>: Medium.</p>
<h3 id="syntax-1"><a class="header" href="#syntax-1">Syntax</a></h3>
<pre><code class="language-C">T hvx_pair_chunked_zip(T x, size_t chunk_size);
T hvx_pair_chunked_unzip(T x, size_t chunk_size);
T hvx_pair_chunked_zip_list(T x, size_t chunk_size, size_t list_size);
T hvx_pair_chunked_unzip_list(T x, size_t chunk_size, size_t list_size);
</code></pre>
<p><code>hvx_pair_chunked_zip</code> and <code>hvx_pair_chunked_unzip</code>
are useful data-dependent data reindexing functions
for block sizes that correspond to 256 bytes.
For example, if the chunk size parameter <code>chunk_size</code> is used in a loop.
Data reorganization following a constant patterns can always be achieved using
<code>ripple_shuffle()</code> or <code>ripple_shuffle_pair()</code>.</p>
<p>The <code>zip</code> and <code>unzip</code> terms come from python.</p>
<ul>
<li>
<p><code>hvx_pair_chunked_zip</code> considers the input <code>x</code> to be a pair
of sequences of chunks of size `chunk_size.
It returns a corresponding (“zipped”) sequence of pairs (of chunks).</p>
<p>Explained from a tensor perspective,
<code>x</code> can be seen as a <code>chunk_size x n x 2</code> tensor,
whose last two dimensions gets transposed, into a <code>chunk_size x 2 x n</code> tensor.</p>
</li>
<li>
<p><code>hvx_pair_chunked_unzip</code> is the opposite operation:
the input block is considered as a sequence of pairs of chunks,
and the output block is the corresponding pair of sequences of chunks.</p>
<p>Explained from a tensor perspective,
<code>x</code> can be seen as a <code>chunk_size x 2 x n</code> tensor,
whose last two dimensions gets transposed, into a <code>chunk_size x n x 2</code> tensor.</p>
</li>
<li>
<p><code>hvx_pair_chunked_zip_list</code> considers <code>x</code> to be a pair of <em>lists</em> of sequences
of chunks.
The sequence size <code>S</code> inside each list is defined by <code>chunk_size</code> and <code>list_size</code> as
<code>128 / sizeof(T) / chunk_size / list_size</code>.
For each list index, it zips both indexed input list elements
into a list of sequences of <code>S</code> zipped pairs of <code>chunk_size</code>-sized chunks.</p>
<p>Seen as a tensor, the input shape would be <code>chunk_size x S x list_size x 2</code>,
while the output shape would be <code>chunk_size x 2 x S x n_lists</code>.</p>
</li>
<li>
<p><code>hvx_pair_chunked_unzip_list</code> performs the opposite operation.
It considers <code>x</code> to be a <em>list</em> of sequences of pairs of chunks.
The input is a list of sequences of pairs of chunks, and
the output is a pair of lists of sequences of chunks.
The sequence size <code>S</code> inside each list is defined by <code>chunk_size</code> and
<code>list_size</code> as <code>128 / sizeof(T) / chunk_size / list_size</code>.
For each list index, <code>hvx_pair_chunked_unzip_list</code> unzips pairs of chunks in
the indexed input sequence into two sequences that are indexed in each element
of the output pair of lists.</p>
<p>Seen as a tensor, the input shape would be <code>chunk_size x 2 x S x list_size</code>,
while the output shape would be <code>chunk_size x S x n_lists x 2</code>.</p>
</li>
</ul>
<h3 id="constraints-1"><a class="header" href="#constraints-1">Constraints</a></h3>
<ul>
<li><code>x</code>’s shape must fit exactly a pair of HVX vectors.</li>
<li><code>chunk_size</code> has to be a power of 2 and can be up to <code>32 / sizeof(T)</code>.</li>
<li><code>list_size</code> must also be a power of two.</li>
</ul>
<h2 id="2x2-subtensor-transposition-for-pairs-of-hvx-vectors"><a class="header" href="#2x2-subtensor-transposition-for-pairs-of-hvx-vectors">2x2 subtensor transposition for pairs of HVX vectors</a></h2>
<p><strong>Performance impact</strong>: Medium.</p>
<h3 id="syntax-2"><a class="header" href="#syntax-2">Syntax</a></h3>
<pre><code class="language-C">T hvx_pair_2x2_transpose(T x, size_t chunk_size);
T hvx_pair_2x2 transpose_inc(T x, size_t chunk_sizes);
T hvx_pair_2x2_transpose_dec(T x, size_t chunk_sizes);
</code></pre>
<ul>
<li>
<p><code>hvx_pair_2x2_transpose</code> considers <code>x</code> as a <code>chunk_size x 2 x n x 2</code> tensor <code>A</code>,
where <code>chunk_size</code> is a power of two.
The returned block is obtained by transposing the second and fourth dimensions,
i.e., transposing <code>2x2</code> sub-tensors of element size <code>chunk_size</code>.
<code>n = 64 / chunk_size</code>.</p>
</li>
<li>
<p><code>hvx_pair_2x2_transpose_inc</code> and <code>hvx_pair_2x2_transpose_dec</code>
accept a non-power of two <code>chunk_sizes</code> parameter.
However, it does not interpret <code>chunk_sizes</code> as a single chunk size,
but instead as a sequence of chunk sizes for which the subtensor transposition
defined by <code>hvx_pair_2x2_transpose</code> must be applied.
Each bit set in <code>chunk_sizes</code> defines a power-of-two chunk_size to be applied
in that sequence.</p>
<ul>
<li><code>hvx_pair_2x2_transpose_inc</code> applies the transpositions hierarchically
by increasing order of chunk sizes, while <code>hvx_pair_2x2_transpose_dec</code>
applies the transpositions hiearchically by decreasing order of chunk sizes.</li>
</ul>
</li>
</ul>
<h3 id="constraints-2"><a class="header" href="#constraints-2">Constraints</a></h3>
<ul>
<li><code>x</code>’s shape must fit exactly a pair of HVX vectors.</li>
<li>In <code>hvx_pair_2x2_transpose()</code>, <code>chunk_size</code> must be a power of two,
and is limited to <code>32 / sizeof(T)</code>.</li>
</ul>
<h2 id="vector-splicing"><a class="header" href="#vector-splicing">Vector splicing</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<h3 id="syntax-3"><a class="header" href="#syntax-3">Syntax</a></h3>
<pre><code class="language-C">T hvx_splice(T high, T low, size_t n);
T hvx_lsplice(T high, T low, size_t n);
</code></pre>
<p>This is a <em>flat</em> operator, which means that it considers a block as being
one-dimensional.
Hence, we describe blocks here as “vector“s.
<code>hvx_splice</code> forms a vector from two vectors <code>high</code> and <code>low</code>.
Let’s call <code>N</code> the number of elements in the vector.
The returned vector contains
the <code>n</code> lowest elements of <code>high</code> as its highest elements,
and the <code>N-n</code> highest elements of <code>low</code> as its lowest elements.</p>
<p><code>hvx_lsplice</code> (“low splice”) forms a vector from two vectors <code>high</code> and <code>low</code>.
The returned vector contains
the <code>n</code> highest elements of <code>low</code> as its lowest elements,
and the <code>N-n</code> lowest elements of <code>high</code> as its highest elements.</p>
<p>This behavior is illustrated on Figure H1.
<img src="./hvx_splice.png" title="hvx_splice behavior" alt="hvx_splice and hvx_lsplice function behavior">
<strong>Figure H1.</strong> hvx_splice/hvx_lsplice behavior</p>
<p><strong>Note</strong>: An implicit “modulo N” is applied to <code>n</code>, to ensure sound semantics.</p>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<p>Typical uses for <code>hvx_splice</code> are codes that use overlapping windows of tensors,
for example in stencils, convolutions and pooling.
Example 2 will be a sliding window, a 1-dimensional Gaussian blur.</p>
<p><code>hvx_splice</code> is also sometimes used to implement padding, as shown in Example 1.</p>
<p><strong>Example 1</strong>: We need to add two arrays, but only one of them has a size
that is a multiple of the HVX vector size (here called <code>HVX_SIZE_U16</code>).</p>
<pre><code class="language-C++">#define HVX_SIZE_U16 64
void padded_add(size_t n, uint16_t * in1_padded, uint16_t * in2_unpadded,
                uint16_t * out_padded) {
  ripple_block_t B = ripple_set_shape(HVX_LANES, HVX_SIZE_U16);
  size_t v = ripple_id(B, 0);
  size_t i;
  // full-vector loop: we know we have full vectors from in1 and in2
  for (i = 0; i &lt; n; i += HVX_SIZE_U16) {
    out_padded[i + v] = in1_padded[i + v] + in2_unpadded[i + v];
  }
  // epilogue: There aren't enough elements in in2_unpadded to add with.
  //           We're splicing that partial vector with a vector of zeros
  out_padded[i + v] = in1_padded[i + v] +
    // we want to specify the #elements taken from the lower vector --&gt; lsplice
                      hvx_lsplice(0, in2_unpadded[i + v], n - i);
}
</code></pre>
<p>Note that the same effect can be obtained using conditionals in this case.
The epilogue code in <code>padded_add</code> below could be replaced with the following
code to obtain the same result.</p>
<pre><code class="language-C++">  out_padded[i + v] = in1_padded[i + v] + (i + v &lt; n) ? in2_unpadded[i + v] : 0;
</code></pre>
<p>The difference between the two lies in the use of predicate registers
in the latter.
The sequence of instructions for the original padded_add epilogue are roughly:</p>
<ul>
<li>Compute <code>n - i</code> (a scalar).</li>
<li>Top off <code>in2_unpadded</code> with zeros using <code>hvx_lsplice</code>.</li>
<li>Add <code>in1_padded</code> with the combined vector</li>
</ul>
<p>The sequence of instruction for the conditional-based version is roughly:</p>
<ul>
<li>Compute the vector predicate for the expression <code>i + v &lt; n</code>.</li>
<li>Select the elements from the zero-vector and <code>in2_unpadded</code>
as specified in the vector predicate.</li>
<li>Add <code>in1_padded</code> with the resulting vector</li>
</ul>
<p>While the number of steps seems comparable,
computing predicates can be more expensive than computing non-predicates.
Hence in this case, the version based on <code>hvx_lsplice</code> is generally preferred.</p>
<p><strong>Example 2</strong>: Stencil operations are often used to write filters,
or iteratively solve partial differential equations.</p>
<p>The following code is a simple gaussian blur operating on a 1-d signal:</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  for (size_t i = 1; i &lt; n - 1; ++i) {
    out[i] = (in[i - 1] + in[i] + in[i + 1]) * one_third;
  }
}
</code></pre>
<p>A naïve vectorization can be obtained by decorating the <code>i</code> loop with
<code>ripple_parallel</code>.
No matter how <code>in</code> and <code>out</code> are align, at least two of the loads of <code>in</code>
will be unaligned.
We can do better by using only aligned loads and stores.</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  constexpr size_t nv = 32;
  constexpr size_t hvx_bytes = nv * sizeof(float);
  ripple_block_t B = ripple_set_shape(HVX_LANES, nv);
  size_t v = ripple_id(B, 0);
  float * in_ptr_lower, * in_ptr, * in_ptr_upper;

  // prologue
  in_ptr = ripple_ptr_alignment(&amp;in[0], hvx_bytes);
  in_ptr_upper = ripple_ptr_alignment(&amp;in[nv], hvx_bytes);
  float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);
  out_ptr[v] = (hvx_lsplice(0, in_ptr, 1) +
               in_ptr[v] +
               hvx_lsplice(in_ptr, in_ptr_upper, 1)) * one_third;

  // steady-state loop
  size_t i;
  for (i = nv; i &lt; n - nv; i += nv) {
    in_ptr = ripple_ptr_alignment(&amp;in[i], hvx_bytes);
    in_ptr_lower = ripple_ptr_alignment(&amp;in[i - nv], hvx_bytes);
    in_ptr_upper = ripple_ptr_alignment(&amp;in[i + nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = // take one extra element from the lower vector
                 (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in[v] +
                  // take one extra element from the upper vector
                  hvx_splice(in_ptr, in_ptr_upper, 1)) * one_third;
  }

  // epilogue
  if (i + v &lt; n) {
    in_ptr = ripple_ptr_alignment(&amp;in[i], hvx_bytes);
    in_ptr_lower = ripple_ptr_alignment(&amp;in[i - nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in_ptr[v] +
                  hvx_lsplice(in_ptr, 0, 1)) * one_third;
  }
}
</code></pre>
<p>The code above is faster than the original code,
because it only involves aligned loads and stores.</p>
<p>We can make it even faster by noticing that consecutive iterations of <code>i</code>
reuse two of the three input vectors.
Hence, instead of re-loading these two vectors,
we can just reuse them from the previous iteration.
This reuse technique, often called “register rotation,”
is applied to <code>gaussian_blur</code> below.</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  constexpr size_t nv = 32;
  constexpr size_t hvx_bytes = nv * sizeof(float);
  ripple_block_t B = ripple_set_shape(HVX_LANES, nv);
  size_t v = ripple_id(B, 0);
  float * in_ptr_lower, * in_ptr, * in_ptr_upper;

  // prologue
  in_ptr = ripple_ptr_alignment(&amp;in[0], hvx_bytes);
  in_ptr_upper = ripple_ptr_alignment(&amp;in[nv], hvx_bytes);
  float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);
  out_ptr[v] = (hvx_lsplice(0, in_ptr, 1) +
                in_ptr[v] +
                hvx_lsplice(in_ptr, in_ptr_upper, 1)) * one_third;

  // steady-state loop
  size_t i;
  for (i = nv; i &lt; n - nv; i += nv) {
    // register rotation: in_ptr -&gt; in_ptr_lower; in_ptr_upper -&gt; in_ptr
    in_ptr_lower = ripple_ptr_alignment(in_ptr, hvx_bytes);
    in_ptr = ripple_ptr_alignment(in_ptr_upper, hvx_bytes);
    // in_ptr_upper is new, still need to load it
    in_ptr_upper = ripple_ptr_alignment(&amp;in[i + nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = // take one extra element from the lower vector
                 (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in[v] +
                  // take one extra element from the upper vector
                  hvx_splice(in_ptr, in_ptr_upper, 1)) * one_third;
  }

  // epilogue
  if (i + v &lt; n) {
    // register rotation applied here as well
    in_ptr_lower = ripple_ptr_alignment(in_ptr, hvx_bytes);
    in_ptr = ripple_ptr_alignment(in_ptr_upper, hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in_ptr[v] +
                  hvx_splice(in_ptr, 0, 1)) * one_third;
  }
}
</code></pre>
<p>Let <code>V</code> the number of HVX vectors in <code>in</code>.
With this transformation, the total number of vector loads from <code>in</code> went from
about <code>3*V</code> to <code>V</code>, without adding any work, a clear performance win.
Note that the versions of <code>gaussian_blur</code> above that use <code>hvx_splice</code> assume
that it’s safe to read up to one vector past the upper boundary of <code>in</code>.
It is possible to remove that limitation by writing slightly more complex code.</p>
<h3 id="constraints-3"><a class="header" href="#constraints-3">Constraints</a></h3>
<p><code>high</code> and <code>low</code> shapes must correspond to
the number of elements in one HVX Vector.</p>
<hr>
<p><em>Copyright (c) 2024-2025 Qualcomm Innovation Center, Inc. All rights reserved.
SPDX-License-Identifier: BSD-3-Clause-Clear</em></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="coalescing.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="profiling.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="coalescing.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="profiling.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
