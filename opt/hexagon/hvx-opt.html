<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>HVX-specific optimization - Ripple HVX Optimization Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-6a08bd33.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-8f2f9eff.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Ripple HVX Optimization Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="hexagon-r-hvx-optimization"><a class="header" href="#hexagon-r-hvx-optimization">Hexagon (R) HVX Optimization</a></h1>
<p>This section is structured as a list of coding recommendations
in order to get competitive performance out of your Ripple programs.</p>
<h1 id="optimization-level"><a class="header" href="#optimization-level">Optimization level</a></h1>
<p>Ripple has been most tested with the <code>-O2</code> option on HVX,
which seems to be the most common optimization level.</p>
<pre><code class="language-bash">clang -O2 ...
</code></pre>
<h1 id="vector-size-parameters"><a class="header" href="#vector-size-parameters">Vector size parameters</a></h1>
<p>Current versions of HVX ISAs tend to come with a register file of 32Kb total.
Please check the appropriate programmer’s manuals for any specific information,
such as number and bit-width of registers,
about the particular architecture version you are compiling for.
The following block sizes illustrate single-vector block sizes
assuming a vector width of 1024 bits.</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>element type</th><th>i8/u8</th><th>i16/u16/f16</th><th>i32/u32/f32</th></tr>
</thead>
<tbody>
<tr><td>single-vector block size</td><td>128</td><td>64</td><td>32</td></tr>
</tbody>
</table>
</div>
<p>Since HVX instruction packets can contain up to four instructions, it is usually not useful to make the size of your block larger than four vectors.
For more information about VLIW slot usage, please consult the Hexagon HVX Programmer’s Reference Manual (available on <code>docs.qualcomm.com</code>).</p>
<h1 id="make-the-type-of-constants-immediates-explicit"><a class="header" href="#make-the-type-of-constants-immediates-explicit">Make the type of constants (“immediates”) explicit</a></h1>
<p><strong>Performance impact</strong>: High.</p>
<p>One thing to remember when coding in Ripple, is that it maintains all semantical aspects of its underlying language.
One aspect of C that can impact performance in C and C++ is their <strong>implicit type conversions</strong>, and the <strong>default type</strong> for its constants.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<p>Consider the following function, which doubles the value of a <code>float</code> array.</p>
<pre><code class="language-c">1:void double_me(float * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 32);
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = 2.0 * A[i];
6:  }
7:}
</code></pre>
<p><strong>Problem</strong>: The <code>2.0</code> immediate is by default a <code>double</code> in C and C++.
Also, type promotion rules in C/C++ indicate that the multiplication line 5 is done after promoting both operands to the same type, <code>double</code>.
Hence, Ripple tries to produce a SIMD multiplication of 32 doubles.
However, current versions of HVX do not support SIMD
double-precision instructions.
As a result, the generated code is sequentialized, resulting in an order of magnitude slower performance than if SIMD could have been used.</p>
<p><strong>Solution</strong>: Make the <code>2.0</code> immediate explicitly of the <code>float</code> type, using the <code>f</code> suffix.</p>
<pre><code class="language-c">5:     A[i] = 2.0f * A[i];
</code></pre>
<p>The same issue can happen with integers, for which the default type is <code>int</code>, as in the following example:</p>
<pre><code class="language-c">1:void double_me(short * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 64);
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = 2 * A[i];
6:  }
7:}
</code></pre>
<p>Here, the <code>2</code> line 5 is an <code>int</code>, and so is the subsequent multiplication,
because of type promotion rules in the C programming language.
<strong>Solution</strong>: convert it to short explicitly.</p>
<pre><code class="language-c">5:    A[i] = ((short) 2) * A[i];
</code></pre>
<p>If you are using C++, precomputing it and forcing it to be a constexpr
will make sure that there is no extra cost to this conversion, as in the following code:</p>
<pre><code class="language-c++">1:void double_me(short * A, unsigned n) {
2:  ripple_block_t b = ripple_set_block_shape(HVX_LANES, 64);
3:  constexpr short two = (short) 2;
3:  ripple_parallel(b, 0);
4:  for (int i = 0; i &lt;n; ++i) {
5:    A[i] = two * A[i];
6:  }
7:}
</code></pre>
<h1 id="optimizing-floating-point-code"><a class="header" href="#optimizing-floating-point-code">Optimizing floating-point code</a></h1>
<h2 id="use-floating-point-types-up-to-32-bit-wide-float-only"><a class="header" href="#use-floating-point-types-up-to-32-bit-wide-float-only">Use floating point types up to 32-bit wide (<code>float</code>) only</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<p>Hexagon supports two native floating-point types: float and _Float16.
__bf16 is partially emulated.
There isn’t currently a native HVX <code>double</code> vector ISA.
Hence, avoid double-precision computations in your vector codes,
which will come out as sequentialized.</p>
<h2 id="leverage-compiler-flags"><a class="header" href="#leverage-compiler-flags">Leverage compiler flags</a></h2>
<h3 id="extended-precision"><a class="header" href="#extended-precision">Extended precision</a></h3>
<p><strong>Performance impact</strong>: Medium.</p>
<p>HVX allows extended-precision computations to happen in sequences of floating-point operations happening between memory accesses.
These are in a way more precise than IEEE floating-point, but they will result in a different numerical result from the same computation performed on IEEE floating point numbers.
It is possible to forgo of extended precision and be fully compatible with IEEE. However, this comes at a performance cost.</p>
<p>The use of fast, extended precision vs. slower, IEEE-compliant precision, is controlled by the following flag:</p>
<pre><code class="language-bash">-mhvx-qfloat=&lt;mode&gt;
</code></pre>
<p>We refer to the HVX manual to describe the exact behavior of the following four modes:</p>
<ul>
<li><code>strict-ieee</code> will give you full compatibility with IEEE floating point.</li>
<li><code>ieee</code> uses extended precision for some operations.</li>
<li><code>lossy</code> uses extended precision for more operations.</li>
<li><code>legacy</code> uses extended precision for almost all operations.</li>
</ul>
<p>As of clang 21.0, the default is set to <code>lossy</code>.
<strong>Warning</strong>: the <code>lossy</code> option also implies other flags that impact precision, such as <code>-ffast-math</code>, which declares that floating-point (+, *) operations are commutative and associative, and that the data is free of <code>NaN</code>s and infinity.</p>
<h3 id="working-with-finite-values"><a class="header" href="#working-with-finite-values">Working with finite values</a></h3>
<p><strong>Performance impact</strong>: Low.</p>
<p>clang is able to optimize some codes when you know that your floating-point values are always defined (they are not a NaN) and never infinite.
If you are in that case, use the <code>-ffinite-only</code> command-line flag.</p>
<h3 id="relaxing-the-ordering-of-computations"><a class="header" href="#relaxing-the-ordering-of-computations">Relaxing the ordering of computations</a></h3>
<p><strong>Performance impact</strong>: Medium.</p>
<p>Addition and multiplication are commutative and associative for real numbers. This means that you can change the order in which a sequence of (for instance) additions (often called “reductions”) are computed without changing the result.
Being able to change this order allows compilers to execute such sequences of operations faster.</p>
<p>Floating point numbers are an approximation for real numbers, and as a consequence, their operations aren’t associative strictly speaking.
Changing the order of floating-point computations typically introduces some amount of precision error.</p>
<p><strong>Solution</strong> If your computation tolerates some amount of floating-point error, or if semantically that order does not matter for the resulting computation, you can let Ripple know it, using the following command-line flag:</p>
<pre><code class="language-bash">clang -fassociative-math
</code></pre>
<p>This will speed up some computations, including reductions (expressed through the <code>ripple_reduce_*()</code> ripple API).</p>
<h3 id="fast-conversions-from-floating-point-to-integer"><a class="header" href="#fast-conversions-from-floating-point-to-integer">Fast conversions from floating-point to integer</a></h3>
<p><strong>Performance impact</strong>: Low.</p>
<p>Conversion from floating-point (<code>Float</code> and <code>float</code> types) to integer
(<code>int16_t</code> and <code>int32_t</code>) can be slow,
as clang tries to implement it as precisely as possible.</p>
<p><strong>Solution</strong> Enable fast floating-point conversion,
which is very close semantically, but uses a single instruction.
To enable it, use the following command-line flag:</p>
<pre><code class="language-bash">clang -mllvm -hexagon-fp-fast-convert=true ...
</code></pre>
<h1 id="using-ripple_shuffle-on-vector-pairs"><a class="header" href="#using-ripple_shuffle-on-vector-pairs">Using ripple_shuffle on vector pairs</a></h1>
<p><strong>Performance impact</strong>: Medium.</p>
<p>We empirically noticed that shuffles on blocks of 2 vectors tend to
generate more efficient machine code.</p>
<h1 id="inlining-functions"><a class="header" href="#inlining-functions">Inlining functions</a></h1>
<p><strong>Performance impact</strong>: High.</p>
<p>For an HVX target, there are significant overheads associated with function calls.
The overheads mostly arise from saving the register frame onto the stack
before the function call and loading the register frame from the stack
after the call returns.
Consequently, we advise the programmer to utilize clang’s
<a href="https://clang.llvm.org/docs/AttributeReference.html#always-inline-force-inline">“always_inline”</a>
function attribute.
Avoid these overheads while maintaining code-readability as follows:</p>
<pre><code class="language-C"> static int foo(int a, int b) __attribute__((always_inline)) {
    /// ...
  }
</code></pre>
<p>or in C++</p>
<pre><code class="language-C++">static int foo(int a, int b) [[gnu::always_inline]] {
    /// ...
  }
</code></pre>
<h1 id="functions-optimized-for-hvx"><a class="header" href="#functions-optimized-for-hvx">Functions optimized for HVX</a></h1>
<h2 id="high-throughput-data-reordering-scattergather"><a class="header" href="#high-throughput-data-reordering-scattergather">High-throughput data reordering (scatter/gather)</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<p>Loading from a collection of arbitrary addresses into a vector
is by construction a long-latency operation,
as it can result in bank conflicts.
Hence, we do not recommend the direct use of non-coalesced access functions.</p>
<p>However, the Ripple vector library includes a
high-bandwidth memory-to-memory copying API for HVX,
which can move large amounts of data in parallel
(still with the same type of latency).</p>
<p>In cases where we cannot change our computations
to create coalesced data accesses, we can still rearrange our data into a set
that can be accessed in a coalesced way a bit later,
using the <code>hvx_gather/hvx_scatter</code> API.</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<pre><code class="language-C">void hvx_gather(T * dst, T * src, OFF_T offset, OFF_T region_size);
void hvx_scatter(T * dst, T src, OFF_T offset, OFF_T region_size);
</code></pre>
<p>These functions launch a high-throughput parallel data reorganization
from memory to memory.
<code>hvx_gather</code> and <code>hvx_scatter</code> are typically beneficial
to reorganize chunks of VTCM data (several or many vectors)
ahead of (for hvx_gather) or after (for hvx_scatter)
a computation that uses the reorganized data in a coalesced way.
The high latency that is inherent to arbitrary data reorganization is
amortized by the ability to run many of these vector reorg operations
concurrently.</p>
<p>There are two possible reorganizations</p>
<ul>
<li>collecting data from arbitrary locations to contiguous blocks
in memory, so that later code can work
with coalesced loads and stores: <code>hvx_gather</code>.</li>
<li>distributing contiguous data to arbitrary locations: <code>hvx_scatter</code>.
This is often done after performing computations on the data in their
contiguous form (i.e., efficiently).</li>
</ul>
<p><code>hvx_gather</code> and <code>hvx_scatter</code> are affected by conditionals
(they become a masked gather or scatter)</p>
<p><code>offset</code> represents the offsets in number of elements,
(as opposed to number of bytes), which are added to <code>src</code> for <code>hvx_gather</code>
and <code>dst</code> for <code>hvx_scatter</code>.
For instance if <code>T</code> is <code>int16_t</code>, the source byte offset is <code>2*src_offset</code>.</p>
<p><code>region_size</code> represents the number of elements in the region,
on the non-coalesced side of the transfer.
Any address going out of that region is ignored
(the transfer of the addressee does not happen).</p>
<p>Notice how <code>hvx_gather</code> and <code>hvx_scatter</code> effectively offer
three ways to mask element data transfers:</p>
<ul>
<li>through masking (using them in a conditional),</li>
<li>through the use of a negative index (preventing underflows), and</li>
<li>through the <code>region_size</code> parameter (preventing overflows).</li>
</ul>
<p>Masking makes the program more readable as it makes this behavior explicit.
On the other hand,
it also introduces a mask computation, which could add
latency to the data transfer.</p>
<p>Use cases for scatter-gather include indirections (<code>A[B[i]]</code>),
large lookup tables, sparse-dense array computations (for instance sparse matrix dense vector multiplication), and strided data accesses, particularly when the data access stride is large (e.g. when accessing element of a large array along columns).</p>
<h3 id="example-1-dense-matrix-x-sparse-vector"><a class="header" href="#example-1-dense-matrix-x-sparse-vector">Example 1: dense matrix x sparse vector</a></h3>
<p>Let us look at a dense-sparse vector inner product
(more often found inside “SpMV”, sparse-matrix-dense-vector products).
The sparse vector <code>S</code> is accompanied with an index (<code>S_index</code>),
representing the coordinates of its non-zero elements.
Let the dense vector be named <code>V</code>.</p>
<p>Let’s start with a straightforward implementation.
Since we only want to perform the multiplications for which S is non-zero,
we select the corresponding elements in <code>V</code>:</p>
<pre><code class="language-C">float SpVV(float * S, int32_t * S_index, size_t nS, float * V) {
  ripple_block_t BS = ripple_set_block_shape(HVX_PE, 32);

  float result = 0.f;
  ripple_parallel(BS, 0);
  for (size_t i = 0; i &lt; nS; ++i) {
    result += S[i] * V[S_index[i]];
  }
  return ripple_reduceadd(0b1, result);
}
</code></pre>
<p>Unfortunately, when vectorized, the indirection in <code>V[S_index[i]]</code> translates
to vector gathers, which are very inefficient.
In particular, they introduce long latencies in the innermost computational
loop.
These latencies tend to add up at each loop iteration, making the overall loop
slow.</p>
<p>The idea here is to still do long-latency gathers, but do a lot of them
in parallel by using <code>hvx_gather</code>
to make all accesses in the inner product loop coalesced.
To simplify the following code, we assume the existence of <code>vtcm_malloc()</code> and
<code>vtcm_free()</code> functions.</p>
<pre><code class="language-C">float SpVV(float * S, int32_t * S_index, size_t nS, float * V, size_t nV) {
  ripple_block_t BS = ripple_set_block_shape(HVX_PE, 32);
  float * gathered_V = vtcm_malloc(sizeof(float) * nS, /*align_as=*/128);
  ripple_parallel(BS, 0);
  for (size_t i = 0; i &lt; nS; ++i) {
    hvx_gather(gathered_V, i, V, S_index[i], /*region_size=*/nV);
  }

  float result = 0.f;
  ripple_parallel(BS, 0);
  for (size_t i = 0; i &lt; nS; ++i) {
    result += S[i] * gathered_V[i];
  }
  vtcm_free(gathered_V);
  return ripple_reduceadd(0b1, result);
}

Since all addresses in the `hvx_gather` loop are conflict-free,
all the data reorganization is done in parallel (up to the limits offered by
the underlying HVX hardware).
Assuming the possibility to run `nS / 32` reorg copies at once,
we are only paying the latency of one copy in the `hvx_gather` loop.
The subsequent inner product loop is optimal in terms of its load/store
latencies, which are all coalesced.

### Constraints
`hvx_gather` and `hvx_scatter` have very specific semantics,
  to be enforced by the developer:
- Both `src` and `dst` have to lie in local memory (VTCM)
- In hvx_gather, `dst` needs to be aligned on a HVX vector boundary.
- `T` can be any base type.
- `OFF_T` can be `int16_t` or `int32_t`.
   Its bitwidth has to match that of the elements being transferred.
  Notice how this limits the offset values to 32767 in the `int16_t` case.
- Transfers of elements for which the index is negative are ignored.
- Addresses in a (hardware) vector transfer cannot cross VTCM page boundary.
  VTCM page size depends upon the configuration.
  As time of writing, it is typically 4 or 8 MB,
  or less if the VTCM is smaller than 4MB.
- The ripple block size must be such that each call to hvx_gather or
  hvx_scatter transfers one native HVX vector.


## Explicit bfloat16 conversions
__Performance impact__: High.

Ripple supports three types of conversions from `float` to `__bf16`:
- `to_bf_trunc`, a direct truncation
- `to_bf_nan`, a truncation that avoids incorrect NaN conversions (they can become an infinity using the direct shift)
- `to_bf_round`, a conversion that performs an even rounding and avoids incorrect Nan conversions. The behavior of this conversion is compatible with x86 bfloat conversion.

## Dynamic rotations
__Performance impact__: Low.

### `hvx_rotate_to_lower`

`hvx_rotate_to_lower` is a rotation across elements of a
block (interpreted as a one-dimensional block).
If B is the block size,
`hvx_rotate_to_lower(x, n)` moves element `k` of `x`
from index `k` to index `k - n modulo B`.
Values of `n` must be between 0 and B - 1.

### Example 1
The following code snippet:

```C
ripple_block_t BS = ripple_set_block_shape(VECTOR_PE, 8);
char alphabet = 'a' + ripple_id(BS, 0);
char rotated_alphabet = hvx_rotate_to_lower(alphabet, 2);
</code></pre>
<p>creates <code>alphabet</code>, a 8-element block with letters <code>a</code> to <code>h</code></p>
<p>| <code>a</code> | <code>b</code> | <code>c</code> | <code>d</code> | <code>e</code> | <code>f</code> | <code>g</code> | <code>h</code> |</p>
<p>and then rotates it down by 2 elements, giving the following block:</p>
<p>| <code>c</code> | <code>d</code> | <code>e</code> | <code>f</code> | <code>g</code> | <code>h</code> | <code>a</code> | <code>b</code> |</p>
<h3 id="example-2-partial-prefix-sum"><a class="header" href="#example-2-partial-prefix-sum">Example 2: Partial prefix sum</a></h3>
<p>In the code below, we use it to implement a partial prefix sum
in a the <code>sum</code> vector.
This means that the <code>k</code>-th element in <code>sum</code> contains the sum of all elements
in <code>input</code> from <code>0</code> to <code>k</code>.</p>
<p>Each iteration of the <code>step</code> loop sums each vector element of index <code>k</code> of <code>sum</code>
with the element of index <code>k-step</code> for all <code>k</code>’s greater than <code>step</code>.
This is done by rotating <code>sum</code> <em>up</em> by <code>step</code> indices.</p>
<p>To rotate up, recall that <code>rotate</code> is cyclical,
hence rotating by <code>block_size - step</code> towards lower indices
is equivalent to rotating by <code>step</code> toward upper indices.</p>
<p>The first iteration (<code>step=1</code>) computes the sum of each element with its direct
neighbor.
The second one sums pairs (leaving the first pair alone using
<code>(v &gt;= step)</code>), then quads, etc.</p>
<p>The resulting partial sum vector is then stored into the <code>output</code> array.</p>
<pre><code class="language-C">#define VECTOR_PE 0
#define VECTOR_SIZE 32
void partial_prefix_sum(int32_t input[VECTOR_SIZE], int32_t output[VECTOR_SIZE]) {
  ripple_block_t BS = ripple_set_block_shape(VECTOR_PE, VECTOR_SIZE);
  size_t block_size = ripple_get_block_size(BS, 0);
  size_t v = ripple_id(BS, 0);

  int32_t sum = input[v];
  for (size_t step = 1; step &lt; block_size; step *= 2) {
    // Shifts to upper by 'step' and adds
    sum += (v &gt;= step) ? hvx_rotate_to_lower(sum, block_size - step) : 0;
  }
  output[v] = sum;
}
</code></pre>
<p><code>hvx_rotate_to_lower</code> can be used on multi-dimensional blocks, in which case
the block will be interpreted as one-dimensional (basically, flattened)
during the rotation.</p>
<h3 id="constraints"><a class="header" href="#constraints">Constraints</a></h3>
<ul>
<li><code>hvx_rotate_to_lower</code> works on blocks that map to a single HVX vector.</li>
<li><code>TYPE</code> can be any one of <code>(u?)int(8|16|32|64)_t</code> and <code>_Float16/float/double</code>.
i.e., <code>dst[i] = src[(i + n) % get_size(N)]</code>
where <code>N</code> is the total size of the block.</li>
</ul>
<h2 id="narrowing-shifts"><a class="header" href="#narrowing-shifts">Narrowing shifts</a></h2>
<p><strong>Performance impact</strong>: Medium.</p>
<h3 id="syntax-1"><a class="header" href="#syntax-1">Syntax</a></h3>
<pre><code class="language-C">narrow_t hvx_narsh[[_rnd]_sat][_noshuff](wide_t odd, wide_t even, uint32 shift);
</code></pre>
<p>A narrowing shift (or “narsh”) is an operation on integers,
which performs a right shift followed by a conversion
to a smaller integer type.
The conversion can be done by truncation or using saturation (using the function name suffix <code>_sat</code>).
When saturation is used, we can also request rounding up, using the
<code>_sat_rnd</code> suffix.
The shift amount sh is the same for all elements of the block.</p>
<p>Two forms are supported. The first, faster form takes two inputs, performs a narrowing shift, and shuffles the resulting block.
The second form, suffixed with <code>_noshuff</code>, doesn’t shuffle the result.</p>
<h3 id="supported-source-and-destination-types-__"><a class="header" href="#supported-source-and-destination-types-__">Supported source and destination types __</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>wide (source) type</th><th>narrow (destination) type</th></tr>
</thead>
<tbody>
<tr><td>i32 (int32_t)</td><td>i16, u16</td></tr>
<tr><td>u32 (uint32_t)</td><td>u16</td></tr>
<tr><td>i16 (int16_t)</td><td>i8, u8</td></tr>
<tr><td>u16</td><td>u8</td></tr>
</tbody>
</table>
</div>
<p>An interesting aspect of this function is that it packs
the narrowed by pairs, i.e. two 32-bit integers get narrowed and packed into one 32-bit integer.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<pre><code class="language-C">int16_t hvx_narsh_sat_i16toi8(int16_t odd, int16_t even, uint32_t shift);
uint32_t hvx_narsh_rnd_sat_u32tou16_noshuff(uint32_t odd, uint32_t even, uint32_t shift);
</code></pre>
<h3 id="constraints-1"><a class="header" href="#constraints-1">Constraints</a></h3>
<p>hvx_narsh works on block sizes that occupy a full HVX vector.</p>
<h2 id="vector-splicing"><a class="header" href="#vector-splicing">Vector splicing</a></h2>
<p><strong>Performance impact</strong>: High.</p>
<h3 id="syntax-2"><a class="header" href="#syntax-2">Syntax</a></h3>
<pre><code class="language-C">T hvx_splice(T high, T low, size_t n);
T hvx_lsplice(T high, T low, size_t n);
</code></pre>
<p>This is a <em>flat</em> operator, which means that it considers a block as being
one-dimensional.
Hence, we describe blocks here as “vector“s.
<code>hvx_splice</code> forms a vector from two vectors <code>high</code> and <code>low</code>.
Let’s call <code>N</code> the number of elements in the vector.
The returned vector contains
the <code>n</code> lowest elements of <code>high</code> as its highest elements,
and the <code>N-n</code> highest elements of <code>low</code> as its lowest elements.</p>
<p><code>hvx_lsplice</code> (“low splice”) forms a vector from two vectors <code>high</code> and <code>low</code>.
The returned vector contains
the <code>n</code> highest elements of <code>low</code> as its lowest elements,
and the <code>N-n</code> lowest elements of <code>high</code> as its highest elements.</p>
<p>This behavior is illustrated on Figure H1.
<img src="./hvx_splice.png" title="hvx_splice behavior" alt="hvx_splice and hvx_lsplice function behavior">
<strong>Figure H1.</strong> hvx_splice/hvx_lsplice behavior</p>
<p><strong>Note</strong>: An implicit “modulo N” is applied to <code>n</code>, to ensure sound semantics.</p>
<p>Typical uses for <code>hvx_splice</code> are codes that use overlapping windows of tensors,
for example in stencils, convolutions and pooling.
Example 2 will be a sliding window, a 1-dimensional Gaussian blur.</p>
<p><code>hvx_splice</code> is also sometimes used to implement padding, as shown in Example 1.</p>
<h3 id="example-1"><a class="header" href="#example-1">Example 1</a></h3>
<p>We need to add two arrays, but only one of them has a size
that is a multiple of the HVX vector size (here called <code>HVX_SIZE_U16</code>).</p>
<pre><code class="language-C++">#define HVX_SIZE_U16 64
void padded_add(size_t n, uint16_t * in1_padded, uint16_t * in2_unpadded,
                uint16_t * out_padded) {
  ripple_block_t B = ripple_set_shape(HVX_LANES, HVX_SIZE_U16);
  size_t v = ripple_id(B, 0);
  size_t i;
  // full-vector loop: we know we have full vectors from in1 and in2
  for (i = 0; i &lt; n; i += HVX_SIZE_U16) {
    out_padded[i + v] = in1_padded[i + v] + in2_unpadded[i + v];
  }
  // epilogue: There aren't enough elements in in2_unpadded to add with.
  //           We're splicing that partial vector with a vector of zeros
  out_padded[i + v] = in1_padded[i + v] +
    // we want to specify the #elements taken from the lower vector --&gt; lsplice
                      hvx_lsplice(0, in2_unpadded[i + v], n - i);
}
</code></pre>
<p>Note that the same effect can be obtained using conditionals in this case.
The epilogue code in <code>padded_add</code> below could be replaced with the following
code to obtain the same result.</p>
<pre><code class="language-C++">  out_padded[i + v] = in1_padded[i + v] + (i + v &lt; n) ? in2_unpadded[i + v] : 0;
</code></pre>
<p>The difference between the two lies in the use of predicate registers
in the latter.
The sequence of instructions for the original padded_add epilogue are roughly:</p>
<ul>
<li>Compute <code>n - i</code> (a scalar).</li>
<li>Top off <code>in2_unpadded</code> with zeros using <code>hvx_lsplice</code>.</li>
<li>Add <code>in1_padded</code> with the combined vector</li>
</ul>
<p>The sequence of instruction for the conditional-based version is roughly:</p>
<ul>
<li>Compute the vector predicate for the expression <code>i + v &lt; n</code>.</li>
<li>Select the elements from the zero-vector and <code>in2_unpadded</code>
as specified in the vector predicate.</li>
<li>Add <code>in1_padded</code> with the resulting vector</li>
</ul>
<p>While the number of steps seems comparable,
computing predicates can be more expensive than computing non-predicates.
Hence in this case, the version based on <code>hvx_lsplice</code> is generally preferred.</p>
<h3 id="example-2"><a class="header" href="#example-2">Example 2</a></h3>
<p>Stencil operations are often used to write filters,
or iteratively solve partial differential equations.</p>
<p>The following code is a simple gaussian blur operating on a 1-d signal:</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  for (size_t i = 1; i &lt; n - 1; ++i) {
    out[i] = (in[i - 1] + in[i] + in[i + 1]) * one_third;
  }
}
</code></pre>
<p>A naïve vectorization can be obtained by decorating the <code>i</code> loop with
<code>ripple_parallel</code>.
No matter how <code>in</code> and <code>out</code> are align, at least two of the loads of <code>in</code>
will be unaligned.
We can do better by using only aligned loads and stores.</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  constexpr size_t nv = 32;
  constexpr size_t hvx_bytes = nv * sizeof(float);
  ripple_block_t B = ripple_set_shape(HVX_LANES, nv);
  size_t v = ripple_id(B, 0);
  float * in_ptr_lower, * in_ptr, * in_ptr_upper;

  // prologue
  in_ptr = ripple_ptr_alignment(&amp;in[0], hvx_bytes);
  in_ptr_upper = ripple_ptr_alignment(&amp;in[nv], hvx_bytes);
  float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);
  out_ptr[v] = (hvx_lsplice(0, in_ptr, 1) +
               in_ptr[v] +
               hvx_lsplice(in_ptr, in_ptr_upper, 1)) * one_third;

  // steady-state loop
  size_t i;
  for (i = nv; i &lt; n - nv; i += nv) {
    in_ptr = ripple_ptr_alignment(&amp;in[i], hvx_bytes);
    in_ptr_lower = ripple_ptr_alignment(&amp;in[i - nv], hvx_bytes);
    in_ptr_upper = ripple_ptr_alignment(&amp;in[i + nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = // take one extra element from the lower vector
                 (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in[v] +
                  // take one extra element from the upper vector
                  hvx_splice(in_ptr, in_ptr_upper, 1)) * one_third;
  }

  // epilogue
  if (i + v &lt; n) {
    in_ptr = ripple_ptr_alignment(&amp;in[i], hvx_bytes);
    in_ptr_lower = ripple_ptr_alignment(&amp;in[i - nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in_ptr[v] +
                  hvx_lsplice(in_ptr, 0, 1)) * one_third;
  }
}
</code></pre>
<p>The code above is faster than the original code,
because it only involves aligned loads and stores.</p>
<p>We can make it even faster by noticing that consecutive iterations of <code>i</code>
reuse two of the three input vectors.
Hence, instead of re-loading these two vectors,
we can just reuse them from the previous iteration.
This reuse technique, often called “register rotation,”
is applied to <code>gaussian_blur</code> below.</p>
<pre><code class="language-C++">void gaussian_blur(size_t n, float * in, float * out) {
  constexpr float one_third = 1.f/3.f;
  constexpr size_t nv = 32;
  constexpr size_t hvx_bytes = nv * sizeof(float);
  ripple_block_t B = ripple_set_shape(HVX_LANES, nv);
  size_t v = ripple_id(B, 0);
  float * in_ptr_lower, * in_ptr, * in_ptr_upper;

  // prologue
  in_ptr = ripple_ptr_alignment(&amp;in[0], hvx_bytes);
  in_ptr_upper = ripple_ptr_alignment(&amp;in[nv], hvx_bytes);
  float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);
  out_ptr[v] = (hvx_lsplice(0, in_ptr, 1) +
                in_ptr[v] +
                hvx_lsplice(in_ptr, in_ptr_upper, 1)) * one_third;

  // steady-state loop
  size_t i;
  for (i = nv; i &lt; n - nv; i += nv) {
    // register rotation: in_ptr -&gt; in_ptr_lower; in_ptr_upper -&gt; in_ptr
    in_ptr_lower = ripple_ptr_alignment(in_ptr, hvx_bytes);
    in_ptr = ripple_ptr_alignment(in_ptr_upper, hvx_bytes);
    // in_ptr_upper is new, still need to load it
    in_ptr_upper = ripple_ptr_alignment(&amp;in[i + nv], hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = // take one extra element from the lower vector
                 (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in[v] +
                  // take one extra element from the upper vector
                  hvx_splice(in_ptr, in_ptr_upper, 1)) * one_third;
  }

  // epilogue
  if (i + v &lt; n) {
    // register rotation applied here as well
    in_ptr_lower = ripple_ptr_alignment(in_ptr, hvx_bytes);
    in_ptr = ripple_ptr_alignment(in_ptr_upper, hvx_bytes);
    float * out_ptr = ripple_ptr_alignment(&amp;out[i], hvx_bytes);

    out_ptr[v] = (hvx_lsplice(in_ptr_lower, in_ptr, 1) +
                  in_ptr[v] +
                  hvx_splice(in_ptr, 0, 1)) * one_third;
  }
}
</code></pre>
<p>Let <code>V</code> the number of HVX vectors in <code>in</code>.
With this transformation, the total number of vector loads from <code>in</code> went from
about <code>3*V</code> to <code>V</code>, without adding any work, a clear performance win.
Note that the versions of <code>gaussian_blur</code> above that use <code>hvx_splice</code> assume
that it’s safe to read up to one vector past the upper boundary of <code>in</code>.
It is possible to remove that limitation by writing slightly more complex code.</p>
<h3 id="constraints-2"><a class="header" href="#constraints-2">Constraints</a></h3>
<p><code>high</code> and <code>low</code> shapes must correspond to
the number of elements in one HVX Vector.</p>
<hr>
<p><em>Copyright (c) 2024-2025 Qualcomm Innovation Center, Inc. All rights reserved.
SPDX-License-Identifier: BSD-3-Clause-Clear</em></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="coalescing.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="profiling.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="coalescing.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="profiling.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
